{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.spatial import distance\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "import urllib.parse\n",
    "client = pymongo.MongoClient(\"mongodb+srv://sparrow:AKyTRpqg8XF88VhU@cluster0.4bymg.mongodb.net/Loco_Trackinator?retryWrites=true&w=majority\")\n",
    "db=client[\"LocoTrackKLU\"]\n",
    "col1=db['students']\n",
    "col2=db['teachers']\n",
    "col3=db['managers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/izaya/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "FR_model = load_model('nn4.small2.v1.h5')\n",
    "#print(\"Total Params:\", FR_model.count_params())\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "threshold = 0.25\n",
    "\n",
    "face_database = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in os.listdir('images'):\n",
    "    for image in os.listdir(os.path.join('images',name)):\n",
    "        identity = os.path.splitext(os.path.basename(image))[0]\n",
    "        face_database[identity] = fr_utils.img_path_to_encoding(os.path.join('images',name,image), FR_model)\n",
    "\n",
    "#print(face_database)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/izaya/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: DeprecationWarning: update is deprecated. Use replace_one, update_one or update_many instead.\n",
      "/home/izaya/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: DeprecationWarning: update is deprecated. Use replace_one, update_one or update_many instead.\n",
      "/home/izaya/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: DeprecationWarning: update is deprecated. Use replace_one, update_one or update_many instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4351\n"
     ]
    }
   ],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "ct=0\n",
    "l=[]\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "        roi = frame[y:y+h, x:x+w]\n",
    "        encoding = img_to_encoding(roi, FR_model)\n",
    "        min_dist = 100\n",
    "        identity = None\n",
    "        for(name, encoded_image_name) in face_database.items():\n",
    "            dist = np.linalg.norm(encoding - encoded_image_name)\n",
    "            if(dist < min_dist):\n",
    "                min_dist = dist\n",
    "                identity = name\n",
    "#print('Min dist: ',min_dist)\n",
    "        if min_dist < 0.1:\n",
    "            ct+=1\n",
    "            #cv2.putText(frame, \"Face : \" + identity[:-1], (x, y - 50), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, \"Dist : \" + str(min_dist), (x, y - 20), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0),2)\n",
    "            #print(identity[:-1].split(\"-\")[0])\n",
    "            IDD=identity[:-1].split(\"-\")[0]\n",
    "            l.append(IDD)\n",
    "            myurl = 'https://ltklu.herokuapp.com/msf/uplocation'\n",
    "            if ct%10==0:\n",
    "                x=max(set(l),key=l.count)\n",
    "                print(x)\n",
    "                #rs = requests.patch(myurl, data={'id':x,'location':'ExpoGlug'})\n",
    "                col1.update({'id':x}, {\"$set\":{'location':'ExpoGlug'}})\n",
    "                col2.update({'id':x}, {\"$set\":{'location':'ExpoGlug'}})\n",
    "                col3.update({'id':x}, {\"$set\":{'location':'ExpoGlug'}})\n",
    "                #print(res.text)\n",
    "        else:\n",
    "            cv2.putText(frame, 'No matching faces', (x, y - 20), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)\n",
    "    cv2.imshow('Face Recognition System', frame)\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
